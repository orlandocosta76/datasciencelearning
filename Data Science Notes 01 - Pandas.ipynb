{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS01 - Pandas 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll cover the following:\n",
    "\n",
    "    - Dropping rows and columns \n",
    "    - Inplace\n",
    "    - Copying dataframes\n",
    "    - Basic math operations with dataframes\n",
    "    - Group by (split/apply/combine)\n",
    "    - Concat\n",
    "    - Sorting the index\n",
    "    - Setting the index\n",
    "    - Resetting the index\n",
    "    - Sorting values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This is an option to preview less rows in the notebook's cells' outputs\n",
    "pd.options.display.max_rows = 6\n",
    "\n",
    "# Read the data in file airbnb_rooms.csv into a pandas DataFrame and use column room_id as the DataFrame index.\n",
    "df = pd.read_csv('data/airbnb_rooms.csv', index_col='room_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to drop rows and columns from a DataFrame, we can use function [drop](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html).\n",
    "\n",
    "In order to drop a row, we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This drops the row with index 17031\n",
    "df.drop(labels=17031) # default axis=0\n",
    "\n",
    "#If we want to drop multiple rows (or columns), we can use lists:\n",
    "df.drop(labels=[6499, 17031])\n",
    "\n",
    "# This drops column neighborhood\n",
    "df.drop(columns='neighborhood') # or df.drop(labels='neighborhood', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns\n",
    "\n",
    "`df = df.rename(columns={'index': 'brewery_id'}) `\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another example with inplace=True:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we're transforming DataFrames, it can be usefull to keep a copy of the original DataFrame.\n",
    "\n",
    "We can do that with function [copy](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.copy.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy function returns a copy of df\n",
    "df_original = df.copy()\n",
    "\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic math operations\n",
    "\n",
    "### Between a constant and a DataFrame column\n",
    "\n",
    "The operation is repeated for each row.\n",
    "\n",
    "For example, if we want to compute the rooms' price per week (7 nights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new column in the DataFrame (price_per_week), where each row is equal to the price * 7\n",
    "df['price_per_week'] = df.price * 7\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Between a two DataFrame columns\n",
    "\n",
    "The operation is performed element-wise, i.e, for each row, we apply the operation between the two columns' values.\n",
    "\n",
    "For instance, if we want to compute the people per bedroom ratio in each room:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new column in the DataFrame (people_per_bedroom), \n",
    "# where each row is equal to the value of the accommodates column divided by the bedrooms column\n",
    "df['people_per_bedroom'] = df.accommodates / df.bedrooms\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(row):\n",
    "    #print (row)\n",
    "    return row[\"host_id\"] + row[\"accommodates\"]* row[\"price\"]\n",
    "\n",
    "df[\"new_col\"] = df.apply(myfunc, axis='columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very extensive topic, and we'll just touch it's surface here, so that you know that exists and can explore it further later by your own.\n",
    "\n",
    "In case you've worked with SQL before, you'll find this very familiar :)\n",
    "\n",
    "So, in Pandas there is process a of three chained steps called [split-apply-combine](https://pandas.pydata.org/pandas-docs/stable/groupby.html):\n",
    "* __split__: splitting the DataFrame into groups (this is the groupby)\n",
    "* __apply__: apply a function to each group (aggregation, transformation and filtration)\n",
    "* __combine__: create a DataFrame with the results\n",
    "\n",
    "Let's see an example!\n",
    "\n",
    "We want to find how many rooms each landlord has.\n",
    "For that, consider this smaller DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smaller = pd.read_csv('data/airbnb_groupby.csv', index_col='room_id')\n",
    "\n",
    "df_smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first step is to group our data by 'host_id'. This returns a DataFrameGroupBy object that by itself doesn't tell us much.\n",
    "\n",
    "However, we can use the group property of the DataFrameGroupBy object to inspect the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_by_host_id = df_smaller.groupby('host_id')\n",
    "\n",
    "df_grouped_by_host_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_by_host_id.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the next step is to apply a function to each group, that aggregates our grouped data. In this case, we want to find the size of each group, i.e, the number of room in each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_by_host_id.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example. Let's find out what's the average price per room and the maximum number of bedrooms per room in our original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset again, as we lost the neighborhood column along the way...\n",
    "df = pd.read_csv('data/airbnb_rooms.csv', index_col='room_id')\n",
    "\n",
    "# Group data by neighborhood\n",
    "df_grouped = df.groupby('neighborhood')\n",
    "\n",
    "# Aggregate the price using the average function and aggregate the bedrooms with the max function\n",
    "df_grouped.agg({'price': ['mean'], 'bedrooms': ['max']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [concat](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html) function can be used to concatenate DataFrames, either along the rows or the columns.\n",
    "\n",
    "Let's see some examples.\n",
    "\n",
    "Imagine we have two DataFrames, one with rooms in Areeiro, and the other with rooms in Benfica.\n",
    "And now we want to concatenate the two DataFrames in order to have a unique DataFrame with all the rooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the rooms in Areeiro\n",
    "df_areeiro = df[df.neighborhood == 'Areeiro']\n",
    "print('We have {} rooms in Areeiro'.format(len(df_areeiro)))\n",
    "\n",
    "# Get all the rooms in Benfica\n",
    "df_benfica = df[df.neighborhood == 'Benfica']\n",
    "print('We have {} rooms in Benfica'.format(len(df_benfica)))\n",
    "\n",
    "# Create a unique DataFrame by concatenating df_areeeiro and df_benfica\n",
    "df_areeiro_benfica = pd.concat([df_areeiro, df_benfica])\n",
    "\n",
    "df_areeiro_benfica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some more data from file __airbnb_locations.csv__.\n",
    "\n",
    "This dataset has the coordinates for each room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations = pd.read_csv('data/airbnb_locations.csv', index_col='room_id')\n",
    "\n",
    "df_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next example is to concatenate df_areeiro_benfica and df_locations on the columns. I.e, we want to add columns __latitude__ and __longitude__ to df_areeiro_benfica.\n",
    "\n",
    "In order to tell function concat that we want to perform the concatenation along the columns, we use the __axis=1__ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames df_areeiro_benfica and df_locations along the columns\n",
    "pd.concat([df_areeiro_benfica, df_locations], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But... What are all those NaN values??\n",
    "\n",
    "Well, there are certain indexes that were only found in df_locations (and not in df_areeiro_benfica).\n",
    "So, in this cases, the concat function fills the missing values with NaN.\n",
    "\n",
    "And what if we only want to keep the rooms that exist in both DataFrames? We use the __join='inner'__ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames df_areeiro_benfica and df_locations along the columns,\n",
    "# only keeping rows that exists in both DataFrames\n",
    "pd.concat([df_areeiro_benfica, df_locations], axis='columns', join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the [sort_index](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_index.html) function, we can sort the DataFrame along the index.\n",
    "\n",
    "For instance, our DataFrame df was already sorted along the index, but we can resort it from bigger to smaller rooms ids, using the __ascending=False__ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df with the index sorted from bigger to smaller room_id\n",
    "df.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resetting the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reset the index of a DataFrame with function [reset_index](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.reset_index.html).\n",
    "This will convert the index into a range from 0 to the length of the DataFrame minus 1.\n",
    "\n",
    "Regarding the old index, we can either keep it by adding it as a column in the DataFrame (__drop=False__, this is the default behaviour) or reset it completely (__drop=True__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index and keeping it as a new column room_id\n",
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index and dropping it -> no new column is added\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With function [set_index](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.set_index.html), we can set a new index for our DataFrame.\n",
    "\n",
    "The old index is dropped.\n",
    "\n",
    "In this function, the __drop=True__ parameter deletes the column to be used as the new index, which is the default behaviour, and __drop=False__ keeps the column unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting column neighborhood as the new index\n",
    "# The neighborhood column is dropped from the DataFrame, this is the default behaviour\n",
    "df.set_index('neighborhood', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting column neighborhood as the new index\n",
    "# The neighborhood column is NOT dropped from the DataFrame\n",
    "df.set_index('neighborhood', drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function [sort_values](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html) can be used to sort the DataFrame along a certain column.\n",
    "\n",
    "For instance, let's sort df from cheapest to more expensive rooms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
